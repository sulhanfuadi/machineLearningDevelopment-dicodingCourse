{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series\n",
    "Multivariate time series adalah rangkaian data di mana setiap titik data terdiri dari beberapa variabel yang diamati atau diukur secara bersamaan dalam interval waktu yang berurutan. Berbeda dengan univariate time series, kita tidak hanya melihat satu variabel pada satu waktu tertentu, tetapi sejumlah variabel yang diamati secara bersamaan. Ini memungkinkan kita untuk memahami bagaimana variabel-variabel tersebut berinteraksi satu sama lain seiring waktu.\n",
    "\n",
    "Dengan kata lain, multivariate time series adalah cara untuk menganalisis dan memodelkan hubungan kompleks antara berbagai variabel dalam rentang waktu tertentu. Ini memberikan insight yang lebih mendalam tentang dinamika sistem yang diamati, memungkinkan kita untuk melihat bagaimana perubahan dalam satu variabel dapat memengaruhi variabel lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kasus ini, kita akan menggunakan sebuah dataset berisikan pengukuran konsumsi daya listrik di satu rumah dengan tingkat pengambilan sampel satu menit selama hampir dua tahun. Tersedia berbagai besaran listrik dan beberapa nilai subpengukuran. Anda dapat mengunduh data pada tautan berikut: [Household Electric Power](https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set) atau langsung mengakses melalui Google Drive yang sudah disediakan menggunakan kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_47476\\513246612.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv('https://drive.google.com/uc?id=1AZRfFoyekqSYpri5183RmJjciRGz_ood', sep=',',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-14 17:19:00</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.140</td>\n",
       "      <td>241.16</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-14 17:20:00</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.46</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-14 17:21:00</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-14 17:22:00</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.000</td>\n",
       "      <td>241.08</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-14 17:23:00</th>\n",
       "      <td>0.544</td>\n",
       "      <td>0.000</td>\n",
       "      <td>241.62</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "datetime                                                                   \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "...                                  ...                    ...      ...   \n",
       "2007-02-14 17:19:00                0.636                  0.140   241.16   \n",
       "2007-02-14 17:20:00                0.552                  0.000   240.46   \n",
       "2007-02-14 17:21:00                0.538                  0.000   239.74   \n",
       "2007-02-14 17:22:00                0.524                  0.000   241.08   \n",
       "2007-02-14 17:23:00                0.544                  0.000   241.62   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "datetime                                                                \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "...                               ...             ...             ...   \n",
       "2007-02-14 17:19:00               2.6             0.0             0.0   \n",
       "2007-02-14 17:20:00               2.2             0.0             0.0   \n",
       "2007-02-14 17:21:00               2.2             0.0             0.0   \n",
       "2007-02-14 17:22:00               2.2             0.0             0.0   \n",
       "2007-02-14 17:23:00               2.2             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  \n",
       "...                             ...  \n",
       "2007-02-14 17:19:00             0.0  \n",
       "2007-02-14 17:20:00             0.0  \n",
       "2007-02-14 17:21:00             0.0  \n",
       "2007-02-14 17:22:00             0.0  \n",
       "2007-02-14 17:23:00             0.0  \n",
       "\n",
       "[86400 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://drive.google.com/uc?id=1AZRfFoyekqSYpri5183RmJjciRGz_ood', sep=',',\n",
    "                     infer_datetime_format=True, index_col='datetime', header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada studi kasus ini, mari kita buat sebuah fungsi untuk melakukan normalisasi menggunakan fungsi berikut.\n",
    "\n",
    "Mengapa kita menggunakan sebuah fungsi? Karena kasus ini merupakan multivariate time series di mana data yang kita gunakan memiliki lebih dari satu fitur, maka dari itu alangkah baiknya membuat sebuah fungsi yang dapat digunakan berulang kali. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_series(data, min, max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data\n",
    "data = df.values\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memastikan jumlah fitur agar tidak keliru untuk menghitung jumlah fitur yang ada mari kita gunakan kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menentukan proporsi data berdasarkan interval waktu yang sudah ditentukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TIME = int(len(data) * 0.5)\n",
    "x_train = data[:SPLIT_TIME]\n",
    "x_valid = data[SPLIT_TIME:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas akan memisahkan data menjadi dua bagian yaitu 50% untuk data latih dan 50% sisanya untuk data uji. Seperti yang Anda ingat, jumlah data yang ada pada kasus ini adalah 86.400 baris sehingga dengan menjalankan kode di atas kita akan membagi masing-masing data menjadi 43.200 baris. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
    "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menentukan parameter untuk membagi data latih dan data uji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_PAST = 24\n",
    "N_FUTURE = 24\n",
    "SHIFT = 1\n",
    "# Kode untuk membuat windowed datasets\n",
    "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
    "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
    "                                 shift=SHIFT)\n",
    "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
    "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
    "                                 shift=SHIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas akan mengubah data yang sebelumnya bertipe dataframe menjadi sebuah windowed dataset. Semua parameter yang diperlukan juga sudah ditentukan hingga akhirnya kita sudah memiliki data window latih dan uji yang siap digunakan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya untuk arsitektur model, gunakan dua buah layer Dense. Perlu Anda perhatikan layer pertama harus memiliki parameter input_shape sesuai dengan ukuran yang sudah kita tentukan sebelumnya yaitu (24, 7). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(N_PAST, N_FEATURES)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(N_FEATURES)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " myCallback memberikan fleksibilitas untuk mengontrol proses pelatihan model berdasarkan kriteria yang ditetapkan. Dalam kasus ini, pelatihan akan berhenti ketika tingkat kinerja model telah mencapai tingkat yang dianggap memadai, yaitu ketika nilai MAE pada data pelatihan dan data validasi sudah cukup rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if (logs.get('mae') < 0.055 and logs.get('val_mae') < 0.055):\n",
    "                self.model.stop_training = True\n",
    " \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kode untuk melakukan menyusun struktur sesuai dengan machine learning\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3) \n",
    "model.compile(loss='mae',\n",
    "                  optimizer= optimizer,\n",
    "                  metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode berikut digunakan untuk memulai proses pelatihan model dengan menggunakan dataset pelatihan train_set; mengevaluasi kinerja model pada setiap epoch menggunakan dataset validasi valid_set; dan menggunakan callback hasil modifikasi myCallback untuk menghentikan pelatihan jika kriteria tertentu terpenuhi. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1344/Unknown \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0828 - mae: 0.0828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0827 - mae: 0.0827 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 2/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0601 - mae: 0.0601 - val_loss: 0.0586 - val_mae: 0.0586\n",
      "Epoch 3/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0597 - mae: 0.0597 - val_loss: 0.0565 - val_mae: 0.0565\n",
      "Epoch 4/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0587 - mae: 0.0587 - val_loss: 0.0561 - val_mae: 0.0561\n",
      "Epoch 5/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0578 - mae: 0.0578 - val_loss: 0.0585 - val_mae: 0.0585\n",
      "Epoch 6/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0579 - mae: 0.0579 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 7/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0574 - mae: 0.0574 - val_loss: 0.0568 - val_mae: 0.0568\n",
      "Epoch 8/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0575 - mae: 0.0575 - val_loss: 0.0566 - val_mae: 0.0566\n",
      "Epoch 9/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0573 - mae: 0.0573 - val_loss: 0.0563 - val_mae: 0.0563\n",
      "Epoch 10/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0565 - val_mae: 0.0565\n",
      "Epoch 11/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0571 - mae: 0.0571 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 12/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0565 - val_mae: 0.0565\n",
      "Epoch 13/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0569 - val_mae: 0.0569\n",
      "Epoch 14/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0560 - val_mae: 0.0560\n",
      "Epoch 15/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0569 - mae: 0.0569 - val_loss: 0.0582 - val_mae: 0.0582\n",
      "Epoch 16/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0566 - mae: 0.0566 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 17/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0563 - mae: 0.0563 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 18/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 19/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0564 - mae: 0.0564 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 20/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 21/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0587 - val_mae: 0.0587\n",
      "Epoch 22/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 23/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 24/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0575 - val_mae: 0.0575\n",
      "Epoch 25/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 26/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0562 - mae: 0.0562 - val_loss: 0.0578 - val_mae: 0.0578\n",
      "Epoch 27/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 28/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0560 - mae: 0.0560 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 29/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0579 - val_mae: 0.0579\n",
      "Epoch 30/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 31/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0580 - val_mae: 0.0580\n",
      "Epoch 32/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0561 - mae: 0.0561 - val_loss: 0.0577 - val_mae: 0.0577\n",
      "Epoch 33/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0572 - val_mae: 0.0572\n",
      "Epoch 34/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0573 - val_mae: 0.0573\n",
      "Epoch 35/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0564 - val_mae: 0.0564\n",
      "Epoch 36/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0557 - val_mae: 0.0557\n",
      "Epoch 37/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 38/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0559 - mae: 0.0559 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 39/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 40/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0558 - mae: 0.0558 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 41/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 42/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0554 - val_mae: 0.0554\n",
      "Epoch 43/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0571 - val_mae: 0.0571\n",
      "Epoch 44/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0570 - val_mae: 0.0570\n",
      "Epoch 45/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 46/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0552 - val_mae: 0.0552\n",
      "Epoch 47/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 48/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0553 - val_mae: 0.0553\n",
      "Epoch 49/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 50/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0567 - val_mae: 0.0567\n",
      "Epoch 51/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0554 - val_mae: 0.0554\n",
      "Epoch 52/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0555 - mae: 0.0555 - val_loss: 0.0549 - val_mae: 0.0549\n",
      "Epoch 53/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 54/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0556 - mae: 0.0556 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 55/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0554 - mae: 0.0554 - val_loss: 0.0554 - val_mae: 0.0554\n",
      "Epoch 56/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0546 - val_mae: 0.0546\n",
      "Epoch 57/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0550 - val_mae: 0.0550\n",
      "Epoch 58/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0551 - val_mae: 0.0551\n",
      "Epoch 59/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0546 - val_mae: 0.0546\n",
      "Epoch 60/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0549 - val_mae: 0.0549\n",
      "Epoch 61/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0555 - val_mae: 0.0555\n",
      "Epoch 62/100\n",
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0549 - val_mae: 0.0549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a75d967530>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set,\n",
    "          validation_data=(valid_set),\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah model berhasil dilatih, sekarang Anda sudah bisa melakukan prediksi dengan menggunakan kode berikut.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1349/1349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.39115024,  0.23268387,  0.030233  ,  0.3779718 , -0.00893612,\n",
       "        0.00388482,  0.85343486], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = model.predict(train_set)\n",
    "train_pred[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
